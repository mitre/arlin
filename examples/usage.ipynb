{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "import arlin.dataset.loaders as loaders\n",
    "from arlin.dataset import XRLDataset\n",
    "from arlin.dataset.collectors import SB3PPODataCollector, SB3PPODatapoint\n",
    "\n",
    "from arlin.generation import generate_clusters, generate_embeddings\n",
    "import arlin.analysis.visualization as viz\n",
    "from arlin.analysis import ClusterAnalyzer, LatentAnalyzer\n",
    "from arlin.samdp import SAMDP\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, force=True)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    # Create environment\n",
    "    env = gym.make(\"LunarLander-v2\")\n",
    "    \n",
    "    # Load the SB3 model from Huggingface\n",
    "    model = loaders.load_hf_sb_model(repo_id=\"sb3/ppo-LunarLander-v2\",\n",
    "                                     filename=\"ppo-LunarLander-v2.zip\",\n",
    "                                     algo_str=\"ppo\")\n",
    "    \n",
    "    # Create the datapoint collector for SB3 PPO Datapoints with the model's policy\n",
    "    collector = SB3PPODataCollector(datapoint_cls=SB3PPODatapoint,\n",
    "                                    policy=model.policy)\n",
    "    \n",
    "    # Instantiate the XRL Dataset\n",
    "    dataset = XRLDataset(env, collector=collector)\n",
    "    \n",
    "    # Fill the dataset with 50k datapoints and add in additional analysis datapoints\n",
    "    dataset.fill(num_datapoints=100)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(dataset: XRLDataset):\n",
    "    \n",
    "    embeddings = generate_embeddings(dataset=dataset,\n",
    "                                     activation_key=\"latent_actors\",\n",
    "                                     perplexity=20,\n",
    "                                     n_train_iter=300,\n",
    "                                     output_dim=2,\n",
    "                                     seed=12345)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "def get_clusters(dataset: XRLDataset, embeddings: np.ndarray):\n",
    "    \n",
    "    clusters = generate_clusters(dataset=dataset,\n",
    "                                 embeddings=embeddings,\n",
    "                                 num_clusters=14)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_latent_analytics(embeddings, clusters, dataset):\n",
    "    grapher = LatentAnalyzer(embeddings, dataset)\n",
    "    \n",
    "    embeddings_data = grapher.embeddings_graph_data()\n",
    "    cluster_data = grapher.clusters_graph_data(clusters)\n",
    "    db_data = grapher.decision_boundary_graph_data()\n",
    "    init_term_data = grapher.initial_terminal_state_data()\n",
    "    ep_prog_data = grapher.episode_prog_graph_data()\n",
    "    conf_data = grapher.confidence_data()\n",
    "    \n",
    "    base_path = os.path.join(\"./outputs/\", \"latent_analytics\")\n",
    "    for data in [(embeddings_data, \"embeddings.png\"),\n",
    "                 (cluster_data, \"clusters.png\"),\n",
    "                 (db_data, \"decision_boundaries.png\"),\n",
    "                 (init_term_data, \"initial_terminal.png\"),\n",
    "                 (ep_prog_data, \"episode_progression.png\"),\n",
    "                 (conf_data, \"confidence.png\")\n",
    "                 ]:\n",
    "        path = os.path.join(base_path, data[1])\n",
    "        \n",
    "        viz.graph_individual_data(path, data[0])\n",
    "    \n",
    "    combined_path = os.path.join(base_path, 'combined_analytics.png')\n",
    "    viz.graph_multiple_data(file_path=combined_path,\n",
    "                                           figure_title='Latent Analytics', \n",
    "                                           graph_datas=[db_data, \n",
    "                                                        conf_data, \n",
    "                                                        cluster_data, \n",
    "                                                        ep_prog_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_cluster_analytics(dataset, clusters):\n",
    "    grapher = ClusterAnalyzer(dataset, clusters)\n",
    "    \n",
    "    cluster_conf = grapher.cluster_confidence()\n",
    "    cluster_rewards = grapher.cluster_rewards()\n",
    "    cluster_values = grapher.cluster_values()\n",
    "    \n",
    "    base_path = os.path.join(\"./outputs\", 'cluster_analytics')\n",
    "    for data in [[cluster_conf, 'cluster_confidence.png'], \n",
    "                 [cluster_rewards, 'cluster_rewards.png'],\n",
    "                 [cluster_values, 'cluster_values.png']\n",
    "                 ]:\n",
    "        path = os.path.join(base_path, data[1])\n",
    "        viz.graph_individual_data(path, data[0])\n",
    "    \n",
    "    combined_path = os.path.join(base_path, 'combined_analytics.png')\n",
    "    viz.graph_multiple_data(file_path=combined_path, \n",
    "                                           figure_title='Cluster Analytics', \n",
    "                                           graph_datas=[cluster_rewards, cluster_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samdp(clusters, dataset):\n",
    "    samdp = SAMDP(clusters, dataset)\n",
    "    \n",
    "    base_path = os.path.join(\"./outputs\", 'samdp')\n",
    "    \n",
    "    complete_graph = samdp.save_complete_graph(f'{base_path}/samdp_complete.png')\n",
    "    likely_graph = samdp.save_likely_paths(f'{base_path}/samdp_likely.png')\n",
    "    simplified_graph = samdp.save_simplified_graph(f'{base_path}/samdp_simplified.png')\n",
    "    \n",
    "    path_path = os.path.join(base_path, f\"samdp_path_14_9\")\n",
    "    \n",
    "    samdp.save_paths(14, \n",
    "                     12, \n",
    "                     f'{path_path}.png')\n",
    "    \n",
    "    samdp.save_paths(14, \n",
    "                     12, \n",
    "                     f'{path_path}_verbose.png', \n",
    "                     verbose=True)\n",
    "    \n",
    "    samdp.save_paths(14, \n",
    "                     12,  \n",
    "                     f'{path_path}_bp.png', \n",
    "                     best_path_only=True)\n",
    "    \n",
    "    samdp.save_all_paths_to(12, \n",
    "                            os.path.join(base_path, f\"samdp_paths_to_12_verbose.png\"),\n",
    "                            verbose=True)\n",
    "    \n",
    "    samdp.save_all_paths_to(12, \n",
    "                            os.path.join(base_path, f\"samdp_paths_to_12.png\"))\n",
    "    \n",
    "    samdp.save_txt(f'{base_path}/samdp.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset()\n",
    "embeddings = get_embeddings(dataset=dataset)\n",
    "clusters = get_clusters(embeddings=embeddings, dataset=dataset)\n",
    "\n",
    "graph_latent_analytics(embeddings=embeddings, clusters=clusters, dataset=dataset)\n",
    "graph_cluster_analytics(dataset=dataset, clusters=clusters)\n",
    "samdp(clusters=clusters, dataset=dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
