{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Attack\n",
    "\n",
    "This notebook looks into how ARLIN can be used to create more effective adversarial attacks. The notebook will show the average reward gained and total number of attacks in various attack scenarios against the same trained RL model:\n",
    "\n",
    "- Random action every step\n",
    "- Worst-case action every step\n",
    "- Worst-case action every 10 steps\n",
    "- Least-preferred action based on threshold (https://arxiv.org/pdf/1703.06748.pdf)\n",
    "- ARLIN-informed actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "import arlin.dataset.loaders as loaders\n",
    "from arlin.dataset import XRLDataset\n",
    "from arlin.dataset.collectors import SB3PPODataCollector\n",
    "from arlin.dataset.collectors.datapoints import SB3PPODatapoint\n",
    "\n",
    "from arlin.generation import generate_clusters, generate_embeddings\n",
    "import arlin.analysis.visualization as viz\n",
    "from arlin.analysis import ClusterAnalyzer, LatentAnalyzer\n",
    "from arlin.samdp import SAMDP\n",
    "import arlin.utils.saving_loading as sl_utils\n",
    "from arlin.adversarial.attacks import run_baseline, run_adversarial, run_arlin\n",
    "from arlin.adversarial.metrics import plot_cosine_sim, plot_divergences, plot_episode_rewards\n",
    "from arlin.adversarial.utils import create_dirs\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, force=True)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = True\n",
    "load_embeddings = True\n",
    "load_clusters = True\n",
    "\n",
    "# Create environment\n",
    "env = gym.make(\"LunarLander-v2\", render_mode='rgb_array')\n",
    "\n",
    "# Load the SB3 model from Huggingface\n",
    "model = loaders.load_hf_sb_model(repo_id=\"sb3/ppo-LunarLander-v2\",\n",
    "                                 filename=\"ppo-LunarLander-v2.zip\",\n",
    "                                 algo_str=\"ppo\")\n",
    "\n",
    "adv_model = loaders.load_sb_model('./models/adv_ppo_lunar.zip', 'ppo')\n",
    "\n",
    "# Create the datapoint collector for SB3 PPO Datapoints with the model's policy\n",
    "collector = SB3PPODataCollector(datapoint_cls=SB3PPODatapoint,\n",
    "                                policy=model.policy)\n",
    "\n",
    "# Instantiate the XRL Dataset\n",
    "dataset = XRLDataset(env, collector=collector)\n",
    "\n",
    "if load_data:\n",
    "    # Load the dataset, embeddings, and clusters\n",
    "    dataset.load('./data/LunarLander-50000.npz')\n",
    "else:\n",
    "    dataset.fill(num_datapoints=50000, randomness=0.2)\n",
    "    dataset.save(file_path='./data/LunarLander-50000.npz')\n",
    "\n",
    "if load_embeddings:\n",
    "    embeddings = sl_utils.load_data(file_path='./data/LunarLander-50000-Embeddings.npy')\n",
    "else:\n",
    "    embeddings = generate_embeddings(dataset=dataset,\n",
    "                                activation_key='latent_actors',\n",
    "                                perplexity=500,\n",
    "                                n_train_iter=1500,\n",
    "                                output_dim=2,\n",
    "                                seed=12345)\n",
    "    sl_utils.save_data(embeddings, './data/LunarLander-50000-Embeddings.npy')\n",
    "\n",
    "if load_clusters:\n",
    "    clusters = sl_utils.load_data(file_path='./data/LunarLander-50000-Clusters.npy')\n",
    "    [start_algo, mid_algo, term_algo] = sl_utils.load_data(file_path='./models/cluster_algos.npy', allow_pickle=True)\n",
    "else:\n",
    "    clusters, start_algo, mid_algo, term_algo = generate_clusters(\n",
    "        dataset,\n",
    "        [\"latent_actors\", \"critic_values\"],\n",
    "        [\"latent_actors\", \"critic_values\"],\n",
    "        [\"latent_actors\", \"critic_values\", \"rewards\"],\n",
    "        20,\n",
    "        seed=1234\n",
    "        )\n",
    "\n",
    "    sl_utils.save_data(clusters, './data/LunarLander-50000-Clusters.npy')\n",
    "    sl_utils.save_data(data=[start_algo, mid_algo, term_algo], file_path='./models/cluster_algos.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARLIN Usage\n",
    "\n",
    "Let's use the ARLIN toolkit to identify when we should be performing our adversarial\n",
    "attack, and which actions we should target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_latent_analytics(embeddings: np.ndarray, \n",
    "                           clusters: np.ndarray, \n",
    "                           dataset: XRLDataset):\n",
    "    \"\"\"Graph visualizations of different latent space analytics over embeddings.\"\"\"\n",
    "    \n",
    "    # Create a grapher to generate data used for analysis.\n",
    "    grapher = LatentAnalyzer(embeddings, dataset)\n",
    "    \n",
    "    embeddings_data = grapher.embeddings_graph_data()\n",
    "    # Clusters\n",
    "    cluster_data = grapher.clusters_graph_data(clusters)\n",
    "    \n",
    "    decision_boundaries = grapher.decision_boundary_graph_data()\n",
    "    # Episode progression\n",
    "    ep_prog_data = grapher.episode_prog_graph_data()\n",
    "    # Greedy action confidence\n",
    "    conf_data = grapher.confidence_data()\n",
    "    \n",
    "    base_path = os.path.join(\".\", \"outputs\", \"attack\", \"latent_analytics\")\n",
    "    \n",
    "    # Graph multiple analytics as subplots in one plot\n",
    "    combined_path = os.path.join(base_path, 'combined_analytics-total.png')\n",
    "    viz.graph_multiple_data(file_path=combined_path,\n",
    "                                           figure_title='Latent Analytics', \n",
    "                                           graph_datas=[ep_prog_data, \n",
    "                                                        conf_data, \n",
    "                                                        decision_boundaries],\n",
    "                                           horizontal=True)\n",
    "    combined_path_2 = os.path.join(base_path, 'combined_analytics-generate.png')\n",
    "    viz.graph_multiple_data(file_path=combined_path_2,\n",
    "                                           figure_title='Latent Analytics', \n",
    "                                           graph_datas=[embeddings_data, \n",
    "                                                        cluster_data],\n",
    "                                           horizontal=True)\n",
    "\n",
    "def graph_cluster_analytics(dataset, clusters):\n",
    "    \"\"\"Graph analytics for each cluster\"\"\"\n",
    "    \n",
    "    # Create grapher to graph cluster analytics\n",
    "    grapher = ClusterAnalyzer(dataset, clusters)\n",
    "    \n",
    "    # for i in range(22, 25):\n",
    "    #     grapher.cluster_state_analysis(i,\n",
    "    #                                    env,\n",
    "    #                                    os.path.join(\".\", \"outputs\", \"attack\", \"cluster_state_analysis\"))\n",
    "\n",
    "    # grapher.cluster_state_analysis(9,\n",
    "    #                                env, \n",
    "    #                                os.path.join(\".\", \"outputs\", \"attack\", \"cluster_state_analysis\"))\n",
    "    \n",
    "    # Mean confidence per cluster\n",
    "    cluster_conf = grapher.cluster_confidence()\n",
    "    # Mean total reward per cluster\n",
    "    cluster_rewards = grapher.cluster_rewards()\n",
    "    # Mean value per cluster\n",
    "    cluster_values = grapher.cluster_values()\n",
    "    \n",
    "    # Graph individual graphs per data\n",
    "    base_path = os.path.join(\".\", \"outputs\", \"attack\", 'cluster_analytics')\n",
    "    \n",
    "    # Graph multiple subplots in one plot\n",
    "    combined_path = os.path.join(base_path, 'combined_analytics.png')\n",
    "    viz.graph_multiple_data(file_path=combined_path, \n",
    "                                           figure_title='Cluster Analytics', \n",
    "                                           graph_datas=[cluster_conf,\n",
    "                                                        cluster_values,\n",
    "                                                        cluster_rewards],\n",
    "                                           horizontal=True)\n",
    "\n",
    "def samdp(clusters: np.ndarray,\n",
    "          dataset: XRLDataset):\n",
    "    \"\"\"Generate a semi-aggregated Markov decision process.\"\"\"\n",
    "    \n",
    "    # Create the SAMDP\n",
    "    samdp = SAMDP(clusters, dataset)\n",
    "    \n",
    "    base_path = os.path.join(\".\", \"outputs\", \"attack\", 'samdp')\n",
    "    \n",
    "    # Simplified graph with all possible connections (regardless of action taken)\n",
    "    simplified_graph = samdp.save_simplified_graph(f'{base_path}/samdp_simplified.png')\n",
    "    complete_graph = samdp.save_complete_graph(f'{base_path}/samdp_complete.png')\n",
    "    \n",
    "    samdp.save_terminal_paths(f'{os.path.join(base_path, f\"samdp_terminals_23\")}.png', \n",
    "                              best_path=True,\n",
    "                              term_cluster_id=23)\n",
    "    \n",
    "    # samdp.save_txt('./outputs/attack/samdp/text.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_latent_analytics(embeddings, clusters, dataset)\n",
    "# graph_cluster_analytics(dataset, clusters)\n",
    "samdp(clusters, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 25\n",
    "baseline_obs, baseline_rew, baseline_renders = run_baseline(env, \n",
    "                                                            model, \n",
    "                                                            num_episodes=num_episodes)\n",
    "\n",
    "rand1_obs, rand1_rew, rand1_div, rand1_renders = run_adversarial('random',\n",
    "                                                             collector,\n",
    "                                                             env,\n",
    "                                                             model,\n",
    "                                                             adv_model,\n",
    "                                                             attack_freq=1,\n",
    "                                                             num_episodes=num_episodes\n",
    "                                                             )\n",
    "\n",
    "rand10_obs, rand10_rew, rand10_div, rand10_renders = run_adversarial('random',\n",
    "                                                             collector,\n",
    "                                                             env,\n",
    "                                                             model,\n",
    "                                                             adv_model,\n",
    "                                                             attack_freq=10,\n",
    "                                                             num_episodes=num_episodes\n",
    "                                                             )\n",
    "\n",
    "adv1_obs, adv1_rew, adv1_div, adv1_renders = run_adversarial('adversarial',\n",
    "                                                             collector,\n",
    "                                                             env,\n",
    "                                                             model,\n",
    "                                                             adv_model,\n",
    "                                                             attack_freq=1,\n",
    "                                                             num_episodes=num_episodes\n",
    "                                                             )\n",
    "\n",
    "adv10_obs, adv10_rew, adv10_div, adv10_renders = run_adversarial('adversarial',\n",
    "                                                             collector,\n",
    "                                                             env,\n",
    "                                                             model,\n",
    "                                                             adv_model,\n",
    "                                                             attack_freq=10,\n",
    "                                                             num_episodes=num_episodes\n",
    "                                                             )\n",
    "\n",
    "pref50_obs, pref50_rew, pref50_div, pref50_renders = run_adversarial('preference',\n",
    "                                                                     collector,\n",
    "                                                                     env,\n",
    "                                                                     model,\n",
    "                                                                     adv_model,\n",
    "                                                                     pref_threshold=0.50,\n",
    "                                                                     num_episodes=num_episodes\n",
    "                                                                     )\n",
    "\n",
    "pref75_obs, pref75_rew, pref75_div, pref75_renders = run_adversarial('preference',\n",
    "                                                                     collector,\n",
    "                                                                     env,\n",
    "                                                                     model,\n",
    "                                                                     adv_model,\n",
    "                                                                     pref_threshold=0.75,\n",
    "                                                                     num_episodes=num_episodes\n",
    "                                                                     )\n",
    "\n",
    "pref90_obs, pref90_rew, pref90_div, pref90_renders = run_adversarial('preference',\n",
    "                                                                     collector,\n",
    "                                                                     env,\n",
    "                                                                     model,\n",
    "                                                                     adv_model,\n",
    "                                                                     pref_threshold=0.90,\n",
    "                                                                     num_episodes=num_episodes\n",
    "                                                                     )\n",
    "\n",
    "arlin_obs, arlin_rew, arlin_div, arlin_renders = run_arlin(collector,\n",
    "                                                           env,\n",
    "                                                           model,\n",
    "                                                           start_algo,\n",
    "                                                           mid_algo,\n",
    "                                                           term_algo,\n",
    "                                                           num_episodes=num_episodes\n",
    "                                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Baseline', 'Adversarial 1', 'Preference .75', 'Preference .90', 'ARLIN']\n",
    "obs = [baseline_obs, adv1_obs, pref75_obs, pref90_obs, arlin_obs]\n",
    "rewards = [baseline_rew, adv1_rew, pref75_rew, pref90_rew, arlin_rew]\n",
    "divergences = [adv1_div, pref75_div, pref90_div, arlin_div]\n",
    "\n",
    "create_dirs('./outputs/attack', names)\n",
    "plot_divergences(divergences, names[1:], './outputs/attack/metrics/kl_divergence.png')\n",
    "\n",
    "num_eval = 10\n",
    "\n",
    "if num_eval > len(baseline_obs):\n",
    "    num_eval = len(baseline_obs)\n",
    "\n",
    "for i in range(num_eval):\n",
    "    cs_save_path = f'./outputs/attack/metrics/cosine_similarity/episode_{i}.png'\n",
    "    rew_save_path = f'./outputs/attack/metrics/episode_rewards/episode_{i}.png'\n",
    "    \n",
    "    cs_obs = [j[i] for j in obs]\n",
    "    plot_cosine_sim(baseline_obs[i], cs_obs, names, cs_save_path)\n",
    "    \n",
    "    rews = [j[i] for j in rewards]\n",
    "    plot_episode_rewards(rews, names, rew_save_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
